---
title: "text_analysis_wrangling"
author: "Lauren Simpson"
date: "11/10/2020"
output: pdf_document
---

```{r setup, include=FALSE}
# Load packages here
library(tidyverse)
library(tidytext)
library(wordcloud)
library(textdata)
library(tm)
library(xtable)

knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
```

## Wrangling Data for General Word Cloud

```{r}
# read in covid tweets csv
covid_tweets <- read_csv("/Users/lauren/Documents/git/Blog-Theory-of-Mind/text analysis/covid19_tweets.csv")

# keep only relevant columns in the dataset
covid_tweets2 <- covid_tweets %>%
  select(date, text, hashtags, source)

## GENERAL WORD CLOUD
# shows the top 50 most common words in tweets

# filter out words related to covid, bc by default all tweets are about covid, and numbers
stopwords2 <- data.frame(word = c("https", "t.co", "amp",
                                  "corona","covid", "covid19", "coronavirus", 
                                  "1", "2", "3", 
                                  "10", "19", "24"))

# split tweet text into unigrams, eliminate stop words and additional stop words
covid_words <- covid_tweets2 %>%
  unnest_tokens(output = word, input = text) %>%
  anti_join(stop_words, by = "word") %>%
  anti_join(stopwords2, by = "word") %>%
  count(word, sort = TRUE) %>%
  filter(n != 2093) # filter out "it's", did not work in stopwords2

# create csv file
write_csv(covid_words, "/Users/lauren/Documents/git/Blog-Theory-of-Mind/text analysis/covid_words.csv")
```

## Wrangling Data for Sentiment Analysis

```{r}
## ALL SENTIMENTS

# retrieving sentiments from the nrc lexicon
nrc_lexicon <- get_sentiments("nrc")

# adding nrc sentiments to the covid tweet unigram dataset (covid_words)
nrc_tweets_sent <- covid_words %>%
  inner_join(nrc_lexicon, by = "word") %>%
  group_by(sentiment) %>%
  summarise(n=n()) %>%
  arrange(desc(n))

# create csv file
write_csv(nrc_tweets_sent, "/Users/lauren/Documents/git/Blog-Theory-of-Mind/text analysis/nrc_tweets_sent.csv")

## ANXIETY AND DEPRESSION RELATED SENTIMENTS

# number of words belonging to anxiety and depression related sentiments
nrc_tweets_words <- covid_words %>%
  inner_join(nrc_lexicon, by = "word") %>%
  # selecting sentiments most relevant to anxiety and depression
  filter(sentiment %in% c("sadness", "fear", "positive", "negative")) %>%
  arrange(sentiment, desc(n)) %>%
  group_by(sentiment) %>%
  slice(1:10) %>%
  # added a-d labels to order plots such that pos/neg and fear/sadness would be paired
  mutate(sentiment_label = case_when(sentiment == "positive" ~ "a) positive", 
                                     sentiment == "negative" ~ "b) negative", 
                                     sentiment == "fear" ~ "c) fear", 
                                     sentiment == "sadness" ~ "d) sadness", TRUE ~ sentiment))

# create csv file
write_csv(nrc_tweets_words, "/Users/lauren/Documents/git/Blog-Theory-of-Mind/text analysis/nrc_tweets_words.csv")
```

## Wrangling Data for Comparison and Commonality Clouds

```{r}
## COMPARISON AND COMMONALITY CLOUDS

# get dataset into the correct format for creating a term document matrix
nrc_tweets_cloud <- covid_words %>%
  inner_join(nrc_lexicon, by = "word") %>%
  filter(sentiment %in% c("sadness", "fear", "positive", "negative")) %>%
  arrange(sentiment, desc(n)) %>%
  group_by(sentiment) %>%
  spread(key = sentiment, value = n) %>%
  replace_na(list(sadness = 0, fear = 0, positive= 0, negative = 0))

# create csv file
write_csv(nrc_tweets_cloud, "/Users/lauren/Documents/git/Blog-Theory-of-Mind/text analysis/nrc_tweets_cloud.csv")
```

